# -*- coding: utf-8 -*-
"""Machine Learning Terapan - Sistem Rekomendasi

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1RUm45lAVG1TGEDcu27pDJglW5OCGDTF6

# Library
"""

import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import seaborn as sns
import plotly.express as px
import plotly.graph_objects as go
from sklearn.preprocessing import MinMaxScaler, LabelEncoder, MultiLabelBinarizer
from sklearn.model_selection import train_test_split
from wordcloud import WordCloud
from sklearn.feature_extraction.text import TfidfVectorizer
from sklearn.metrics.pairwise import cosine_similarity
import tensorflow as tf
from tensorflow.keras import Model, layers, models
from tensorflow.keras.callbacks import EarlyStopping
from tensorflow.keras.layers import Embedding, Input, Dot, Flatten, Dense
from sklearn.metrics import precision_score, recall_score, f1_score
import random
import keras
import warnings
warnings.filterwarnings("ignore")

# Untuk tampilan visual yang lebih menarik
sns.set(style="whitegrid", palette="muted", font_scale=1.1)

"""# Data Understanding"""

# Baca data
df_movies = pd.read_csv('/content/movies.csv')
df_ratings = pd.read_csv('/content/ratings.csv')
df_tags = pd.read_csv('/content/tags.csv')

# Gabungkan tag berdasarkan userId dan movieId
df_tags_grouped = df_tags.groupby(['userId', 'movieId'])['tag'].agg(lambda x: ' '.join(x)).reset_index()

# Merge movies dan ratings dan tags berdasarkan 'movieId'
df_temp = pd.merge(df_ratings, df_movies, on='movieId')
df = pd.merge(df_temp, df_tags_grouped, on=['userId', 'movieId'], how='left')

# Lihat hasil akhir
print(f'Dataset shape: {df.shape}')
df.head()

df.info()

# cek duplikat
print("Jumlah duplikat: ", df.duplicated().sum())

# cek missing value
print("Jumlah missing value: ")
print(df.isnull().sum())

# Statistik deskriptif
df.describe().T.style.background_gradient(cmap='YlGnBu').format(precision=2)

# --- Distribusi Rating ---
sns.histplot(df['rating'], bins=10, kde=True, color='skyblue')
plt.title('Distribusi Rating Film')
plt.xlabel('Rating')
plt.ylabel('Jumlah')
plt.show()

"""Gambar di atas memperlihatkan sebaran rating yang diberikan pengguna terhadap film di dalam dataset. Terlihat bahwa mayoritas pengguna cenderung memberikan rating pada skala menengah hingga tinggi, khususnya di angka 4 dan 5. Hal ini menunjukkan adanya bias positif dalam proses evaluasi, yang merupakan fenomena umum dalam sistem rating terbuka, di mana pengguna cenderung hanya memberikan penilaian terhadap film yang mereka sukai atau telah mereka pilih secara selektif."""

# --- Film Paling Banyak Di-rating ---
top_movies = df['title'].value_counts().head(10)
sns.barplot(y=top_movies.index, x=top_movies.values, palette='viridis')
plt.title('10 Film dengan Jumlah Rating Terbanyak')
plt.xlabel('Jumlah Rating')
plt.ylabel('Judul Film')
plt.show()

"""Visualisasi di atas menunjukkan sepuluh film dengan jumlah rating terbanyak dari pengguna dalam dataset sistem rekomendasi film. Film dengan rating terbanyak adalah Forrest Gump (1994) dengan 329 rating, diikuti oleh The Shawshank Redemption (1994) dan Pulp Fiction (1994) dengan masing-masing 317 dan 307 rating. Sebagian besar film yang masuk dalam daftar ini merupakan film klasik dari era 1990-an, yang menandakan adanya kecenderungan pengguna untuk memberikan rating terhadap film-film ikonik atau yang memiliki nilai nostalgia tinggi."""

# --- Genre Paling Umum ---
# Pisahkan genre karena bisa lebih dari satu per film
genre_list = df['genres'].dropna().str.split('|').explode()
top_genres = genre_list.value_counts().head(10)

sns.barplot(x=top_genres.values, y=top_genres.index, palette='coolwarm')
plt.title('10 Genre Film Terpopuler')
plt.xlabel('Jumlah Film')
plt.ylabel('Genre')
plt.show()

"""Bar chart ini menunjukkan distribusi sepuluh genre film yang paling banyak muncul berdasarkan jumlah rating yang tercatat dalam dataset. Genre Drama merupakan yang paling dominan dengan total 41.928 entri, diikuti oleh Comedy (39.053), Action (30.635), dan Thriller (26.452). Urutan ini mencerminkan kecenderungan pengguna untuk lebih banyak menonton dan memberi rating pada film-film dengan narasi kuat atau hiburan populer. Genre Adventure, Romance, dan Sci-Fi juga memiliki jumlah signifikan, menandakan bahwa variasi tema menjadi faktor penting dalam konsumsi film. Di sisi lain, genre seperti Fantasy (11.834) dan Children (9.208) menunjukkan keterwakilan yang lebih rendah, yang bisa jadi disebabkan oleh segmentasi usia pengguna atau keterbatasan dalam ketersediaan konten genre tersebut dalam dataset."""

# --- Rata-rata Rating per Genre ---
genre_ratings = df.copy()
genre_ratings['genre'] = genre_ratings['genres'].str.split('|')
genre_ratings = genre_ratings.explode('genre')

avg_genre_rating = genre_ratings.groupby('genre')['rating'].mean().sort_values(ascending=False).head(10)
sns.barplot(x=avg_genre_rating.values, y=avg_genre_rating.index, palette='magma')
plt.title('Rata-rata Rating Tertinggi per Genre')
plt.xlabel('Rata-rata Rating')
plt.ylabel('Genre')
plt.show()

"""Bar chart ini menunjukkan sepuluh genre film dengan rata-rata rating tertinggi dalam dataset. Genre Film-Noir berada di peringkat pertama dengan nilai rata-rata sebesar 3,92, disusul oleh War (3,81) dan Documentary (3,80), yang menunjukkan bahwa film dalam genre-genre ini cenderung mendapat apresiasi lebih tinggi dari pengguna. Meskipun tidak selalu menjadi genre dengan jumlah penilaian terbanyak, tingginya rata-rata ini mengindikasikan adanya persepsi kualitas atau nilai artistik yang lebih kuat pada genre-genre tersebut. Genre seperti Crime dan Drama yang lebih umum juga masuk dalam daftar, sementara genre yang lebih spesifik seperti IMAX dan Western menunjukkan kualitas yang relatif tinggi meskipun tidak terlalu dominan secara kuantitatif."""

# --- Pengguna Paling Aktif ---
top_users = df['userId'].value_counts().head(10)
sns.barplot(x=top_users.index.astype(str), y=top_users.values, palette='pastel')
plt.title('10 Pengguna Paling Aktif Memberi Rating')
plt.xlabel('User ID')
plt.ylabel('Jumlah Rating')
plt.show()

"""Bar chart ini menampilkan sepuluh pengguna dengan jumlah rating terbanyak dalam dataset, yang menunjukkan tingkat aktivitas individu dalam memberikan evaluasi terhadap film. Pengguna dengan ID 414 tercatat sebagai yang paling aktif dengan total 2.698 rating, disusul oleh ID 599 (2.478 rating) dan ID 474 (2.108 rating). Seluruh pengguna dalam daftar ini telah memberikan lebih dari seribu rating, menunjukkan konsistensi dan keterlibatan tinggi dalam interaksi dengan data film. Pola ini mencerminkan adanya sekelompok kecil pengguna yang berkontribusi secara signifikan terhadap volume data, yang umum ditemukan dalam distribusi partisipasi berbasis pengguna, di mana sebagian besar kontribusi berasal dari minoritas pengguna yang sangat akti"""

# --- WordCloud dari Tag ---
tags = df_tags  ['tag'].dropna().str.lower().str.cat(sep=' ')
wordcloud = WordCloud(width=800, height=400, background_color='white').generate(tags)

plt.figure(figsize=(12, 6))
plt.imshow(wordcloud, interpolation='bilinear')
plt.axis('off')
plt.title('Word Cloud dari Tag Film')
plt.show()

"""Word cloud ini merepresentasikan kata-kata kunci atau tag yang paling sering diasosiasikan dengan film dalam dataset, di mana ukuran kata mencerminkan frekuensi kemunculannya. Tag seperti netflix queue, thought provoking, superhero, sci-fi, dan comedy muncul dalam ukuran besar, menunjukkan bahwa tema-tema tersebut sering digunakan untuk mendeskripsikan atau mengkategorikan film. Kehadiran kata-kata seperti surreal, psychology, mental illness, dan dark comedy mengindikasikan adanya preferensi pengguna terhadap film-film dengan tema kompleks, atmosferik, atau emosional. Di sisi lain, tag seperti high school, time travel, dan action menunjukkan keberagaman dalam genre dan konteks cerita.

# Data Preprocessing

## Content Based Filtering
"""

# Gabungkan genre + tag jadi fitur konten
df['tag'] = df['tag'].fillna('')
df['content'] = df['genres'].fillna('') + ' ' + df['tag']

# Ambil satu baris per film
df_content = df.groupby('movieId').agg({
    'title': 'first',
    'content': lambda x: ' '.join(x)
}).reset_index()

df_content = pd.merge(df_content, df_movies[['movieId', 'genres']], on='movieId', how='left')

# TF-IDF Vectorizer
tfidf = TfidfVectorizer(stop_words='english')
tfidf_matrix = tfidf.fit_transform(df_content['content'])

# Hitung similarity antar film
cosine_sim = cosine_similarity(tfidf_matrix, tfidf_matrix)

"""## Collaborative Filtering"""

# Encode userId dan movieId
user_enc = LabelEncoder()
movie_enc = LabelEncoder()
df_cf = df[['userId', 'movieId', 'rating']].dropna().copy()
df_cf['user'] = user_enc.fit_transform(df_cf['userId'])
df_cf['movie'] = movie_enc.fit_transform(df_cf['movieId'])

# Collect sum unique user and movie
n_users = df_cf['user'].nunique()
n_movies = df_cf['movie'].nunique()

# Train-test split
X = df_cf[['user', 'movie']]
y = df_cf['rating']
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)

# Scaling data
scaler = MinMaxScaler()
y_train_scaled = scaler.fit_transform(y_train.values.reshape(-1, 1))
y_test_scaled = scaler.transform(y_test.values.reshape(-1, 1))

"""# Modelling and Result

## Content Based Filtering
"""

# Fungsi CBF
def recommend_for_user_content_based(title, df=df_content, similarity=cosine_sim, top_n=5):
    idx = df[df['title'].str.lower() == title.lower()].index
    if len(idx) == 0:
        return "Film tidak ditemukan."

    idx = idx[0]
    input_title = df.iloc[idx]['title']
    input_genre = df.iloc[idx]['genres'].replace('|', ', ')

    sim_scores = list(enumerate(similarity[idx]))
    sim_scores = sorted(sim_scores, key=lambda x: x[1], reverse=True)[1:top_n+1]
    movie_indices = [i[0] for i in sim_scores]

    recommendations = df.iloc[movie_indices][['title', 'genres']].reset_index(drop=True)
    recommendations['genres'] = recommendations['genres'].str.replace('|', ', ', regex=False)

    # Mengembalikan hasil rekomendasi
    return recommendations, input_title, input_genre

# Memanggil fungsi dan mendapatkan hasil rekomendasi
recommendations, input_title, input_genre = recommend_for_user_content_based("Jumanji (1995)", top_n=5)

# Print hasilnya di luar fungsi
if isinstance(recommendations, str):  # Jika hasilnya error (film tidak ditemukan)
    print(recommendations)
else:
    print(f"🎬 Judul yang Dicari: {input_title}")
    print(f"🎭 Genre: {input_genre}\n")
    print(f"🔝 Top {len(recommendations)} Rekomendasi dari \"{input_title}\":")

    for i, row in recommendations.iterrows():
        print(f"{i+1}. {row['title']} - Genre: {row['genres']}")

"""## Collaborative Filtering"""

# Model Rekomendasi dengan Embedding Layer
class RecommenderNet(tf.keras.Model):
    def __init__(self, num_users, num_items, embedding_size, **kwargs):
        super(RecommenderNet, self).__init__(**kwargs)
        self.num_users = num_users
        self.num_items = num_items
        self.embedding_size = embedding_size

        # Layer embedding untuk user
        self.user_embedding = layers.Embedding(
            num_users,
            embedding_size,
            embeddings_initializer='he_normal',
            embeddings_regularizer=tf.keras.regularizers.l2(1e-6)
        )
        self.user_bias = layers.Embedding(num_users, 1)  # Bias untuk user

        # Layer embedding untuk item (lagu)
        self.item_embedding = layers.Embedding(
            num_items,
            embedding_size,
            embeddings_initializer='he_normal',
            embeddings_regularizer=tf.keras.regularizers.l2(1e-6)
        )
        self.item_bias = layers.Embedding(num_items, 1)  # Bias untuk item

    def call(self, inputs):
        # Ambil embedding user dan item
        user_vector = self.user_embedding(inputs[:, 0])
        user_bias = self.user_bias(inputs[:, 0])
        item_vector = self.item_embedding(inputs[:, 1])
        item_bias = self.item_bias(inputs[:, 1])

        # Hitung dot product antara embedding user dan item
        dot_user_item = tf.tensordot(user_vector, item_vector, axes=2)

        # Menambahkan bias
        x = dot_user_item + user_bias + item_bias

        # Sigmoid activation untuk output (probabilitas)
        return tf.nn.sigmoid(x)

# Inisialisasi model
model = RecommenderNet(n_users, n_movies, 50)

# Compile model
model.compile(
    loss=tf.keras.losses.MeanSquaredError(),
    optimizer=tf.keras.optimizers.Adam(learning_rate=0.001),
    metrics=[tf.keras.metrics.RootMeanSquaredError()]
)

# Callback EarlyStopping dengan pemberitahuan
early_stopping = EarlyStopping(monitor='val_loss', patience=5, restore_best_weights=True)

# Fungsi custom untuk pemberitahuan jika training berhenti
class PrintStopping(tf.keras.callbacks.Callback):
    def on_epoch_end(self, epoch, logs=None):
        if self.model.stop_training:
            print(f"\nTraining dihentikan pada epoch {epoch + 1}, karena tidak ada perbaikan pada 'val_loss'.")

# Gabungkan callback untuk pemberitahuan dan EarlyStopping
callbacks = [early_stopping, PrintStopping()]

# Training model dengan callback
history = model.fit(
    X_train, y_train_scaled,
    epochs=100,
    batch_size=64,
    validation_data=(X_test, y_test_scaled),
    verbose=1,
    callbacks=callbacks
)

# Plotting Loss dan RMSE
plt.figure(figsize=(12, 6))

# Plot Loss
plt.subplot(1, 2, 1)
plt.plot(history.history['loss'], label='Training Loss', color='b')
plt.plot(history.history['val_loss'], label='Validation Loss', color='r')
plt.title('Training and Validation Loss')
plt.xlabel('Epochs')
plt.ylabel('Loss')
plt.legend()
plt.ylim(0, max(max(history.history['loss']), max(history.history['val_loss'])))  # Batas Y mulai dari 0

# Plot RMSE
plt.subplot(1, 2, 2)
plt.plot(history.history['root_mean_squared_error'], label='Training RMSE', color='b')
plt.plot(history.history['val_root_mean_squared_error'], label='Validation RMSE', color='r')
plt.title('Training and Validation RMSE')
plt.xlabel('Epochs')
plt.ylabel('RMSE')
plt.legend()
plt.ylim(0, max(max(history.history['root_mean_squared_error']), max(history.history['val_root_mean_squared_error'])))  # Batas Y mulai dari 0

plt.tight_layout()
plt.show()

# Evaluasi
test_loss, test_rmse = model.evaluate(X_test.values, y_test_scaled)
print(f"Test RMSE: {test_rmse:.4f}")

# Fungsi rekomendasi film untuk user tertentu
def recommend_for_user_collaborative(user_raw_id, top_n=5):
    user_id = user_enc.transform([user_raw_id])[0]

    # Film yang sudah ditonton user dan ratingnya
    watched_movies = df_cf[df_cf['user'] == user_id][['movie', 'rating']].sort_values(by='rating', ascending=False)

    # Top 5 film yang sudah ditonton berdasarkan rating
    top_watched = watched_movies.head(top_n).reset_index(drop=True)  # Reset index

    # Film yang belum ditonton oleh user
    watched_movie_ids = watched_movies['movie'].tolist()
    all_movie_ids = np.setdiff1d(np.arange(n_movies), watched_movie_ids)

    user_input = np.array([[user_id, mid] for mid in all_movie_ids])
    predictions = model.predict(user_input).flatten()
    top_indices = predictions.argsort()[-top_n:][::-1]
    recommended_movie_ids = all_movie_ids[top_indices]
    recommended_titles = movie_enc.inverse_transform(recommended_movie_ids)

    # Kembalikan hasil rekomendasi dan top watched
    recommended_movies = df_movies[df_movies['movieId'].isin(recommended_titles)][['title', 'genres']]

    return top_watched, recommended_movies

# Pilih user ID secara acak dari data rating
random_user = random.choice(df_cf['user'].unique())
user_raw_id = user_enc.inverse_transform([random_user])[0]

# Panggil fungsi rekomendasi
top_watched, recommended_movies = recommend_for_user_collaborative(user_raw_id, top_n=5)

# Print top watched movies
print(f"🎬 Top 5 Film yang Sudah Ditonton oleh User {user_raw_id}:")
top_watched = top_watched.reset_index(drop=True)
for i, row in top_watched.iterrows():
    movie_id = int(row['movie'])  # pastikan tipe datanya integer
    movie_row = df_movies[df_movies['movieId'] == movie_id]
    if not movie_row.empty:
        movie_title = movie_row['title'].values[0]
        movie_genre = movie_row['genres'].values[0].replace('|', ', ')
        print(f"{i+1}. {movie_title} - Genre: {movie_genre} - Rating: {row['rating']}")
    else:
        print(f"{i+1}. Movie ID {movie_id} not found in movie list.")

# Print recommended movies
recommended_movies = recommended_movies.reset_index(drop=True)
print(f"\n🔝 Top 5 Rekomendasi dari User {user_raw_id}:")
for i, row in recommended_movies.iterrows():
    genre = row['genres'].replace('|', ', ')
    print(f"{i+1}. {row['title']} - Genre: {genre}")

"""# Evaluation

## Content Based Filtering
"""

# Fungsi ubah genre ke str
def genre_to_set(genre_str):
    # Pastikan genre_str adalah list, kalau bukan, ubah ke list
    if isinstance(genre_str, str):
        return set(genre_str.lower().split(', '))
    elif isinstance(genre_str, list):
        return set([g.lower() for g in genre_str])
    else:
        return set()

# Fungsi hitung metrik dari genre
def genre_match_score(true_genres, pred_genres_list):
    true_set = genre_to_set(true_genres)

    precisions, recalls, f1_scores = [], [], []

    for pred_genres in pred_genres_list:
        pred_set = genre_to_set(pred_genres)

        # Precision, Recall, dan F1-Score
        precision = len(true_set & pred_set) / len(pred_set) if len(pred_set) > 0 else 0
        recall = len(true_set & pred_set) / len(true_set) if len(true_set) > 0 else 0
        f1 = 2 * precision * recall / (precision + recall) if (precision + recall) > 0 else 0

        precisions.append(precision)
        recalls.append(recall)
        f1_scores.append(f1)

    avg_precision = sum(precisions) / len(precisions) if precisions else 0
    avg_recall = sum(recalls) / len(recalls) if recalls else 0
    avg_f1 = sum(f1_scores) / len(f1_scores) if f1_scores else 0

    return avg_precision, avg_recall, avg_f1

# Evaluate CBF
def evaluate_content_based_user(user_id, top_n=5):
    # Ambil film yang telah ditonton user
    watched_merged = pd.merge(df_content, df_cf[df_cf['user'] == user_id], left_on='movieId', right_on='movie')

    # Pilih film secara acak dari film yang sudah ditonton oleh user
    sampled_movie = watched_merged.sample(1).iloc[0]

    title = sampled_movie['title']
    true_genre = sampled_movie['genres'].replace('|', ', ')

    # Ambil rekomendasi berdasarkan content-based filtering
    recommendations, input_title, input_genre = recommend_for_user_content_based(title, top_n=top_n)

    # Dapatkan genre film yang direkomendasikan
    pred_genres_list = recommendations['genres'].tolist()

    # Hitung precision, recall, dan f1-score
    precision, recall, f1 = genre_match_score(true_genre, pred_genres_list)

    return user_id, title, precision, recall, f1

# Evaluate CBF dari multi user
def evaluate_content_based_multiple_users(n_users=10, top_n=5, random_state=0):
    # Sampling user secara acak
    np.random.seed(random_state)
    sampled_users = np.random.choice(df_cf['user'].unique(), size=n_users, replace=False)

    results = []
    for user_id in sampled_users:
        uid, title, p, r, f = evaluate_content_based_user(user_id, top_n)
        results.append({
            'userId': uid,
            'sampled_title': title,
            'precision': p,
            'recall': r,
            'f1_score': f
        })

    # Menghitung rata-rata
    result_df = pd.DataFrame(results)
    avg_precision = result_df['precision'].mean()
    avg_recall = result_df['recall'].mean()
    avg_f1 = result_df['f1_score'].mean()

    # Menambahkan baris rata-rata
    result_df.loc['Average'] = ['Average', '-', avg_precision, avg_recall, avg_f1]

    return result_df

# Result evaluasi CBF
cb_result_table = evaluate_content_based_multiple_users(n_users=10, top_n=5)
cb_result_table

"""## Collaborative Filtering"""

# Konversi genre string ke set
def genre_to_set(genre_str):
    return set(genre_str.split('|'))

# Evaluate CF
def evaluate_genre_similarity(user_raw_id, top_n=5):
    try:
        top_watched, recommended_movies = recommend_for_user_collaborative(user_raw_id, top_n=top_n)

        # Gabungkan semua genre dari film yang ditonton
        true_genres_set = set()
        for _, row in top_watched.iterrows():
            movie_id = int(row['movie'])
            movie_row = df_movies[df_movies['movieId'] == movie_id]
            if not movie_row.empty:
                true_genres_set |= genre_to_set(movie_row['genres'].values[0])

        # Gabungkan semua genre dari film yang direkomendasikan
        predicted_genres_set = set()
        for _, row in recommended_movies.iterrows():
            predicted_genres_set |= genre_to_set(row['genres'])

        if not true_genres_set or not predicted_genres_set:
            raise ValueError("Genre kosong.")

        # Binarisasi genre
        mlb = MultiLabelBinarizer()
        y_true = mlb.fit_transform([true_genres_set])
        y_pred = mlb.transform([predicted_genres_set])

        # Hitung metrik
        precision = precision_score(y_true, y_pred, average='macro', zero_division=0)
        recall = recall_score(y_true, y_pred, average='macro', zero_division=0)
        f1 = f1_score(y_true, y_pred, average='macro', zero_division=0)

        sample_titles = [df_movies[df_movies['movieId'] == int(mid)]['title'].values[0]
                         if not df_movies[df_movies['movieId'] == int(mid)].empty else "N/A"
                         for mid in top_watched['movie']]

        return {
            'userId': user_raw_id,
            'sample_titles': sample_titles,
            'precision': precision,
            'recall': recall,
            'f1': f1
        }
    except Exception as e:
        print(f"⚠️ Gagal mengevaluasi user {user_raw_id}: {e}")
        return {
            'userId': user_raw_id,
            'sample_titles': [],
            'precision': 0,
            'recall': 0,
            'f1': 0
        }

# Fungsi evaluasi untuk banyak user
def evaluate_multiple_users_genre_similarity(n_users=10, top_n=5):
    np.random.seed(0)
    random_users = random.sample(list(df_cf['user'].unique()), n_users)
    user_ids_raw = user_enc.inverse_transform(random_users)

    results = []
    for user_raw_id in user_ids_raw:
        result = evaluate_genre_similarity(user_raw_id, top_n=top_n)
        results.append(result)

    df_result = pd.DataFrame(results)
    mean_precision = df_result['precision'].mean()
    mean_recall = df_result['recall'].mean()
    mean_f1 = df_result['f1'].mean()

    print("\n📊 Rata-rata Evaluasi:")
    print(f"Precision: {mean_precision:.4f}")
    print(f"Recall   : {mean_recall:.4f}")
    print(f"F1-Score : {mean_f1:.4f}")

    return df_result

# Jalankan evaluasi
df_eval = evaluate_multiple_users_genre_similarity(n_users=10, top_n=5)

# Tampilkan hasil
pd.set_option("display.max_colwidth", None)
print("\n📋 Hasil Evaluasi per User:")
df_eval[['userId', 'sample_titles', 'precision', 'recall', 'f1']]